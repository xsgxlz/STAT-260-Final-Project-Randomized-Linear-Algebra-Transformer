{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time stamp: 2025-04-03 20-04-16\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import random\n",
    "import copy\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torchtnt.utils.flops import FlopTensorDispatchMode\n",
    "\n",
    "sys.path.append(\"/jet/home/azhang19/stat 260/STAT-260-Final-Project-Randomized-Linear-Algebra-Transformer\")\n",
    "from RLALLaMA3.LLaMA3 import ModelArgs\n",
    "from RLALLaMA3.utils import (\n",
    "    linear_warmup_cosine_decay_multiplicative,\n",
    "    name_args,\n",
    "    transformer_forward_pass,\n",
    "    Args,\n",
    ")\n",
    "from RLALLaMA3.tasks import single_answer_seq_loss, get_dataset\n",
    "\n",
    "def set_seed(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "torch.set_float32_matmul_precision(\"high\")\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "#import torch._dynamo\n",
    "#torch._dynamo.config.suppress_errors = True\n",
    "\n",
    "time_stamp = time.strftime(\"%Y-%m-%d %H-%M-%S\", time.localtime())\n",
    "print(f\"Time stamp: {time_stamp}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.9707)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from RLALLaMA3.RLACore import projection_sketch_mm\n",
    "A = torch.randn(1, 1, 256, 256).to(device)\n",
    "B = torch.randn(256, 256).to(device)\n",
    "gt = A @ B\n",
    "(projection_sketch_mm(A, B, 128) - gt).square().sum() / gt.square().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Args Configuration:\n",
      "\n",
      "Training Parameters:\n",
      "  model_type:         node\n",
      "  standard_lr:        3.2e-03\n",
      "  standard_epoch:     80000\n",
      "  standard_warmup_steps: 4000\n",
      "  batch_size:         1024\n",
      "  min_lr:             1.0e-04\n",
      "  grad_clip_max_norm: 1.0\n",
      "  use_amp:            True\n",
      "  use_compile:        True\n",
      "\n",
      "Data Parameters:\n",
      "  task:               number_add\n",
      "  max_level:          40\n",
      "  random_seq_len:     True\n",
      "  number_range:       (0, 99)\n",
      "\n",
      "Model Architecture Parameters:\n",
      "  dim:                256\n",
      "  n_layers:           2\n",
      "  n_heads:            4\n",
      "  hidden_dim:         896\n",
      "\n",
      "RLA Parameters:\n",
      "  sketch_mode:        rademacher\n",
      "  deterministic:      True\n",
      "  attn_qkv_sketch:    48\n",
      "  attn_out_sketch:    36\n",
      "  ffn_in_sketch:      48\n",
      "  ffn_out_sketch:     48\n",
      "  attn_score_sketch:  24\n",
      "  attn_sum_sketch:    24\n",
      "\n",
      "Save Path Parameters:\n",
      "  save_path:          /accounts/grad/zhangyunzhe2023/Neural-ODE/ckpt\n",
      "  final_save_path:    /accounts/grad/zhangyunzhe2023/Neural-ODE/ckpt_final\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define the arguments\n",
    "##args = parse_args()\n",
    "args = Args(\n",
    "    # Training\n",
    "    standard_lr=3.16e-3,\n",
    "    standard_epoch=80000,\n",
    "    standard_warmup_steps=4000,\n",
    "    batch_size=1024,\n",
    "    min_lr=1e-4,\n",
    "    grad_clip_max_norm=1.0,\n",
    "    use_amp=True,\n",
    "    use_compile=True,\n",
    "    # model_type uses default 'node'\n",
    "\n",
    "    # Data\n",
    "    task=\"number_add\",\n",
    "    max_level=40,\n",
    "    random_seq_len=True,\n",
    "    number_range=(0, 99), # Explicitly provided, overrides default_factory if needed\n",
    "\n",
    "    # Model\n",
    "    dim=256,\n",
    "    n_layers=2,\n",
    "    n_heads=4,\n",
    "    hidden_dim=896,\n",
    "\n",
    "    # RLA parameters (using defaults from the dataclass definition)\n",
    "    sketch_mode='rademacher',\n",
    "    deterministic=True,\n",
    "    attention_qkv_sketch_size=48,\n",
    "    attention_out_sketch_size=36,\n",
    "    feedforward_sketch_size_in=48,\n",
    "    feedforward_sketch_size_out=48,\n",
    "    attention_score_sketch_size=24,\n",
    "    attention_weighed_sum_sketch_size=24,\n",
    "\n",
    "    # Save\n",
    "    save_path=\"/accounts/grad/zhangyunzhe2023/Neural-ODE/ckpt\",\n",
    "    final_save_path=\"/accounts/grad/zhangyunzhe2023/Neural-ODE/ckpt_final\",\n",
    ")\n",
    "\n",
    "\n",
    "print(args, end=\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the data\n",
    "dataset, collate_fn, vocab_size, max_seq_len = get_dataset(args.task,\n",
    "                                                           args.max_level,\n",
    "                                                           args.random_seq_len,\n",
    "                                                           args.number_range,\n",
    "                                                           nested_tensor=False,\n",
    "                                                           pad_to_longest=True)\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=args.batch_size, collate_fn=collate_fn,\n",
    "                                         num_workers=torch.get_num_threads(), pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean sequence length: 63.691806640625\n",
      "Max sequence length: 126\n"
     ]
    }
   ],
   "source": [
    "def mean_seq_len(dataloader, num_samples=100):\n",
    "    \"\"\"\n",
    "    Calculate the mean sequence length of the dataset.\n",
    "    \"\"\"\n",
    "    total_len = 0\n",
    "    num_samples = min(num_samples, len(dataloader.dataset))\n",
    "    for i, x in enumerate(dataloader):\n",
    "        if i >= num_samples:\n",
    "            break\n",
    "        total_len += x[1].float().mean().item()\n",
    "    return total_len / num_samples\n",
    "\n",
    "mean_len = mean_seq_len(dataloader)\n",
    "print(f\"Mean sequence length: {mean_len}\")\n",
    "print(f\"Max sequence length: {max_seq_len}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the model\n",
    "\n",
    "transformer_args = ModelArgs(\n",
    "    dim=args.dim,\n",
    "    n_layers=args.n_layers,\n",
    "    n_heads=args.n_heads,\n",
    "    hidden_dim=args.hidden_dim,\n",
    "    vocab_size=vocab_size,\n",
    "    norm_eps=1e-5,\n",
    "    rope_theta=500000,\n",
    "    max_seq_len=max_seq_len,\n",
    "\n",
    "    sketch_mode = 'rademacher',\n",
    "    attention_qkv_sketch_size = args.attention_qkv_sketch_size,\n",
    "    attention_out_sketch_size = args.attention_out_sketch_size,\n",
    "    feedforward_sketch_size_in = args.feedforward_sketch_size_in,\n",
    "    feedforward_sketch_size_out = args.feedforward_sketch_size_out,\n",
    "    attention_score_sketch_size = args.attention_score_sketch_size,\n",
    "    attention_weighed_sum_sketch_size = args.attention_weighed_sum_sketch_size,\n",
    "    deterministic = args.deterministic,\n",
    ")\n",
    "\n",
    "from RLALLaMA3.LLaMA3 import Transformer\n",
    "model = Transformer(params=transformer_args)\n",
    "\n",
    "model = model.to(device).train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flops (Set): 16647192576\n",
      "Flops (Deterministic): 16647192576\n",
      "Flops (Ratio): 1.0\n"
     ]
    }
   ],
   "source": [
    "with torch.inference_mode():\n",
    "    model.deterministic_mode(args.deterministic)\n",
    "    model.eval()\n",
    "    # Check the model\n",
    "    toy_input = torch.randint(0, vocab_size, (args.batch_size, max_seq_len), device=device)\n",
    "    with FlopTensorDispatchMode(model) as ftdm:\n",
    "        res = model(toy_input)\n",
    "    flops_0 = sum(i for i in ftdm.flop_counts[''].values())\n",
    "\n",
    "    model.deterministic_mode(True)\n",
    "    with FlopTensorDispatchMode(model) as ftdm:\n",
    "        res = model(toy_input)\n",
    "    flops_1 = sum(i for i in ftdm.flop_counts[''].values())\n",
    "model.deterministic_mode(args.deterministic)\n",
    "model.train()\n",
    "\n",
    "print(f\"Flops (Set): {flops_0}\")\n",
    "print(f\"Flops (Deterministic): {flops_1}\")\n",
    "print(f\"Flops (Ratio): {flops_1 / flops_0}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "262622674944\n"
     ]
    }
   ],
   "source": [
    "model = model.deterministic_mode(True)\n",
    "with FlopTensorDispatchMode(model) as ftdm:\n",
    "    res = model(toy_input)\n",
    "print(sum(i for i in ftdm.flop_counts[''].values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rla_mm_flops_ratio(m, d, n, k):\n",
    "    return k/m + k/n + k/d\n",
    "\n",
    "def k_for_target_ratio(m, d, n, target_ratio):\n",
    "    # Calculate the sum of reciprocals\n",
    "    inv_sum = (1/n) + (1/m) + (1/d)\n",
    "    if inv_sum <= 0: # Should not happen with positive dims\n",
    "            return None\n",
    "    # Solve for k: k = target_ratio / (1/n + 1/m + 1/d)\n",
    "    k_needed = target_ratio / inv_sum\n",
    "    # Return the ceiling as k must be an integer\n",
    "    return k_needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating FLOPs ratios/needed k assuming L=126, D=256, H=896, D_h=64, N_h=4\n",
      "Target FLOPs Ratio for k calculation: 0.50\n",
      "\n",
      "Attention QKV Projection (Current k=48):\n",
      "  m=126, d=256, n=768\n",
      "  Current FLOPs Ratio ≈ 0.6310\n",
      "  Approx k needed for ratio 0.50 ≈ 38.0377358490566\n",
      "--------------------\n",
      "Attention Output Projection (Current k=36):\n",
      "  m=126, d=256, n=256\n",
      "  Current FLOPs Ratio ≈ 0.5670\n",
      "  Approx k needed for ratio 0.50 ≈ 31.748031496062993\n",
      "--------------------\n",
      "FeedForward Input Projection (Current k=48):\n",
      "  m=126, d=256, n=1792\n",
      "  Current FLOPs Ratio ≈ 0.5952\n",
      "  Approx k needed for ratio 0.50 ≈ 40.32\n",
      "--------------------\n",
      "FeedForward Output Projection (Current k=48):\n",
      "  m=126, d=896, n=256\n",
      "  Current FLOPs Ratio ≈ 0.6220\n",
      "  Approx k needed for ratio 0.50 ≈ 38.58373205741627\n",
      "--------------------\n",
      "SDPA QK^T Calculation (Current k=24):\n",
      "  m=126, d=64, n=126\n",
      "  Current FLOPs Ratio ≈ 0.7560\n",
      "  Approx k needed for ratio 0.50 ≈ 15.874015748031496\n",
      "--------------------\n",
      "SDPA Scores@V Calculation (Current k=24):\n",
      "  m=126, d=126, n=64\n",
      "  Current FLOPs Ratio ≈ 0.7560\n",
      "  Approx k needed for ratio 0.50 ≈ 15.874015748031496\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "target_flop_ratio = 0.5 # Example target ratio (e.g., 50% reduction)\n",
    "\n",
    "# Model dimensions\n",
    "D = args.dim\n",
    "H = args.hidden_dim\n",
    "L = max_seq_len\n",
    "N_h = args.n_heads\n",
    "if N_h <= 0 or D % N_h != 0:\n",
    "    print(f\"Warning: Invalid n_heads ({N_h}) or dim ({D}). Setting head_dim to D.\")\n",
    "    D_h = D\n",
    "else:\n",
    "    D_h = D // N_h\n",
    "\n",
    "# Output dimension for QKV linear layer\n",
    "D_qkv_out = D * 3\n",
    "# Output dimension for FFN input layer\n",
    "D_ffn_in_out = H * 2\n",
    "\n",
    "print(f\"Calculating FLOPs ratios/needed k assuming L={L}, D={D}, H={H}, D_h={D_h}, N_h={N_h}\")\n",
    "print(f\"Target FLOPs Ratio for k calculation: {target_flop_ratio:.2f}\\n\")\n",
    "\n",
    "# Helper function to print results\n",
    "def print_rla_part_info(part_name, m, d, n, current_k, target_ratio):\n",
    "    if current_k > 0:\n",
    "        ratio = rla_mm_flops_ratio(m, d, n, current_k)\n",
    "        print(f\"{part_name} (Current k={current_k}):\")\n",
    "        print(f\"  m={m}, d={d}, n={n}\")\n",
    "        print(f\"  Current FLOPs Ratio ≈ {ratio:.4f}\")\n",
    "    else:\n",
    "        print(f\"{part_name} (Current k=N/A - Deterministic):\")\n",
    "        print(f\"  m={m}, d={d}, n={n}\")\n",
    "        print(f\"  Current FLOPs Ratio = 1.0000\")\n",
    "\n",
    "    k_needed = k_for_target_ratio(m, d, n, target_ratio)\n",
    "    if k_needed is not None:\n",
    "        print(f\"  Approx k needed for ratio {target_ratio:.2f} ≈ {k_needed}\")\n",
    "    else:\n",
    "        print(f\"  Target ratio {target_ratio:.2f} not achievable or dims invalid.\")\n",
    "    print(\"-\" * 20)\n",
    "\n",
    "# 1. Attention QKV Projection\n",
    "print_rla_part_info(\"Attention QKV Projection\", L, D, D_qkv_out, args.attention_qkv_sketch_size, target_flop_ratio)\n",
    "\n",
    "# 2. Attention Output Projection\n",
    "print_rla_part_info(\"Attention Output Projection\", L, D, D, args.attention_out_sketch_size, target_flop_ratio)\n",
    "\n",
    "# 3. FeedForward Input Projection\n",
    "print_rla_part_info(\"FeedForward Input Projection\", L, D, D_ffn_in_out, args.feedforward_sketch_size_in, target_flop_ratio)\n",
    "\n",
    "# 4. FeedForward Output Projection\n",
    "print_rla_part_info(\"FeedForward Output Projection\", L, H, D, args.feedforward_sketch_size_out, target_flop_ratio)\n",
    "\n",
    "# 5. SDPA QK^T Calculation\n",
    "print_rla_part_info(\"SDPA QK^T Calculation\", L, D_h, L, args.attention_score_sketch_size, target_flop_ratio)\n",
    "\n",
    "# 6. SDPA Scores@V Calculation\n",
    "print_rla_part_info(\"SDPA Scores@V Calculation\", L, L, D_h, args.attention_weighed_sum_sketch_size, target_flop_ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Derived Parameters:\n",
      "lr: 0.00632\n",
      "warmup_steps: 2000\n",
      "epochs: 40000\n",
      "grad_clip_max_norm: 1.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Training configuration\n",
    "standard_lr = args.standard_lr / 512\n",
    "standard_epoch = args.standard_epoch * 512\n",
    "standard_warmup_steps = args.standard_warmup_steps * 512\n",
    "batch_size = args.batch_size\n",
    "\n",
    "lr = standard_lr * batch_size\n",
    "warmup_steps = standard_warmup_steps // batch_size\n",
    "epochs = standard_epoch // batch_size\n",
    "\n",
    "print(\"Derived Parameters:\")\n",
    "print(f\"lr: {lr}\")\n",
    "print(f\"warmup_steps: {warmup_steps}\")\n",
    "print(f\"epochs: {epochs}\")\n",
    "print(f\"grad_clip_max_norm: {args.grad_clip_max_norm}\", end=\"\\n\\n\")\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=lr, fused=True)\n",
    "scheduler = torch.optim.lr_scheduler.MultiplicativeLR(optimizer,\n",
    "            lr_lambda=lambda step: linear_warmup_cosine_decay_multiplicative(step, warmup_steps, epochs, args.min_lr))\n",
    "\n",
    "scaler = torch.amp.GradScaler(device, enabled=args.use_amp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model and arguments\n",
    "\n",
    "def save_record(path, model, record, args, time_stamp, extra_info=None):\n",
    "    dict_name, file_name = name_args(args, \"_\")\n",
    "\n",
    "    os.makedirs(f\"{path}/{dict_name}\", exist_ok=True)\n",
    "    file_name = file_name + f\"_{time_stamp}\"\n",
    "    if extra_info is not None:\n",
    "        file_name += f\"_{extra_info}\"\n",
    "    \n",
    "    record_dict = {\n",
    "        \"model\": model,\n",
    "        \"record\": record,\n",
    "        \"args\": args,\n",
    "        \"time_stamp\": time_stamp,\n",
    "    }\n",
    "        \n",
    "    torch.save(record_dict, f\"{path}/{dict_name}/{file_name}.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Backwards pass\n",
    "def backward_pass(model, loss, optimizer, scaler, scheduler, grad_clip_max_norm):\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    scaler.scale(loss).backward()\n",
    "    scaler.unscale_(optimizer)\n",
    "    torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=grad_clip_max_norm)\n",
    "    scaler.step(optimizer)\n",
    "    scaler.update()\n",
    "    scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.compile(disable=not args.use_compile)\n",
    "def train_step(model, train_data, mean_len, optimizer, scheduler, scaler, args):\n",
    "    device = train_data[0].device\n",
    "    \n",
    "    with torch.autocast(device_type=device.type, dtype=torch.bfloat16, enabled=args.use_amp):\n",
    "        tokens, lengths, ans_starts, ans_lengths = train_data\n",
    "        pred = transformer_forward_pass(tokens[:, :-1], model)\n",
    "        \n",
    "        result = single_answer_seq_loss(pred, tokens, lengths, ans_starts, ans_lengths)\n",
    "        GPT_loss, full_seq_acc, ans_region_acc, ans_char_acc = result\n",
    "        # Normalize the GPT loss by the batch size but not the sequence length\n",
    "        GPT_loss = GPT_loss / args.batch_size\n",
    "        total_loss = GPT_loss\n",
    "        total_loss_for_backward = total_loss / mean_len\n",
    "    \n",
    "    if torch.isnan(total_loss) or torch.isinf(total_loss):# or (total_loss > smoothed_loss * 1.1):\n",
    "        return [total_loss]\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        safe_params = [copy.deepcopy(i.state_dict()) for i in [model, optimizer, scheduler]]\n",
    "\n",
    "    backward_pass(model, total_loss_for_backward, optimizer, scaler, scheduler, args.grad_clip_max_norm)\n",
    "    \n",
    "    data = [GPT_loss, 0, total_loss, full_seq_acc, ans_region_acc, ans_char_acc]\n",
    "    \n",
    "    data += [0, 0]\n",
    "    \n",
    "    with torch.inference_mode():\n",
    "        data = torch.tensor(data).cpu().numpy()\n",
    "\n",
    "    return data, safe_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "record = np.zeros((epochs, 9))\n",
    "num_NaNs = 0\n",
    "smoothed_loss = None\n",
    "\n",
    "safe_params = [copy.deepcopy(i.state_dict()) for i in [model, optimizer, scheduler]]\n",
    "\n",
    "epoch = 0\n",
    "\n",
    "for train_data in dataloader:\n",
    "    if epoch >= epochs:\n",
    "        break\n",
    "\n",
    "    train_data = [x.to(device) for x in train_data]\n",
    "\n",
    "    t0 = time.time()\n",
    "\n",
    "    result = train_step(model, train_data, mean_len, optimizer, scheduler, scaler, args)\n",
    "\n",
    "    if len(result) == 1:\n",
    "        data = result\n",
    "        total_loss = data[0]\n",
    "        num_NaNs += 1\n",
    "        print(f\"Epoch: {epoch}\")\n",
    "        print(\"Instability detected\")\n",
    "        print(f\"Total Loss: {total_loss.item()}\\n\")\n",
    "        model.load_state_dict(safe_params[0])\n",
    "        optimizer.load_state_dict(safe_params[1])\n",
    "        scheduler.load_state_dict(safe_params[2])\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "        continue\n",
    "\n",
    "    data, safe_params = result\n",
    "    smoothed_loss = 0.99 * smoothed_loss + 0.01 * data[2].item() if smoothed_loss is not None else data[2].item()\n",
    "    epoch = epoch + 1\n",
    "\n",
    "    record[epoch - 1, :-1] = data\n",
    "    record[epoch - 1, -1] = num_NaNs\n",
    "        \n",
    "    names = [\"GPT loss\", \"Energy Reg\", \"Total_loss\", \"Full Seq Acc\",\n",
    "             \"Ans Region Acc\", \"Ans Char Acc\", \"Mean Steps\", \"Std Steps\", \"Num NaNs\"]\n",
    "\n",
    "    print(f\"Epoch: {epoch}\")\n",
    "    for name, value in zip(names, data):\n",
    "        print(f\"{name}: {value}\")\n",
    "    print(f\"Smoothed Loss: {smoothed_loss}\")\n",
    "    print(f\"Time: {time.time() - t0}\\n\")\n",
    "\n",
    "    if epoch % 100 == 0:\n",
    "        #save_record(args.save_path, model, record, args, time_stamp)\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save_record(args.final_save_path, model, record, args, time_stamp, smoothed_loss)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "neuralode",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
